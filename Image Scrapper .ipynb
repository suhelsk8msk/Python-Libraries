{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "347fe225-c24e-4712-81ef-80edf28f85b2",
   "metadata": {},
   "source": [
    "# Image Scrapper Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3d580f-f804-4d86-bff4-d99453dc617b",
   "metadata": {},
   "source": [
    "\n",
    "https://www.youtube.com/@PW-Foundation/videos\n",
    "\n",
    "Q1. Write a python program to extract the video URL of the first five videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c65ffbbb-cd5d-473c-bc1e-579f39fca771",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL of the YouTube channel\n",
    "url = \"https://www.youtube.com/@PW-Foundation/videos\"\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Find all elements with the class 'yt-simple-endpoint' (these are the links to videos)\n",
    "video_links = soup.find_all('a', class_='yt-simple-endpoint')\n",
    "\n",
    "# Extract the video URLs of the first five videos\n",
    "first_five_video_urls = []\n",
    "for link in video_links[:5]:\n",
    "    video_url = \"https://www.youtube.com\" + link.get('href')\n",
    "    first_five_video_urls.append(video_url)\n",
    "\n",
    "\n",
    "for index, video_url in enumerate(first_five_video_urls, start=1):\n",
    "    print(f\"Video {index}: {video_url}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd9534d-5cfa-41fd-9bb1-02c0bb5bc0da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a17d57a7-2f47-4816-b993-f45e55c2c3eb",
   "metadata": {},
   "source": [
    "Q2. Write a python program to extract the URL of the video thumbnails of the first five videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "644298f0-9d45-4972-ab98-3cb2d17a6857",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL of the YouTube channel\n",
    "url = \"https://www.youtube.com/@PW-Foundation/videos\"\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Find all elements with the class 'yt-simple-endpoint' (these are the links to videos)\n",
    "video_links = soup.find_all('a', class_='yt-simple-endpoint')\n",
    "\n",
    "# Extract the URLs of the video thumbnails of the first five videos\n",
    "first_five_thumbnail_urls = []\n",
    "for link in video_links[:5]:\n",
    "    thumbnail_url = link.find_next('img').get('src')\n",
    "    first_five_thumbnail_urls.append(thumbnail_url)\n",
    "\n",
    "# Print the thumbnail URLs\n",
    "for index, thumbnail_url in enumerate(first_five_thumbnail_urls, start=1):\n",
    "    print(f\"Thumbnail {index}: {thumbnail_url}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a4b35d-49b2-42f4-93f4-dd16b8872c40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6824f2d7-5e3d-4fbf-a150-c940856a6dc7",
   "metadata": {},
   "source": [
    "Q3. Write a python program to extract the title of the first five videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d209f991-1b02-4ba7-a4b2-eac33107647d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL of the YouTube channel\n",
    "url = \"https://www.youtube.com/@PW-Foundation/videos\"\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Find all elements with the class 'yt-simple-endpoint' (these are the links to videos)\n",
    "video_links = soup.find_all('a', class_='yt-simple-endpoint')\n",
    "\n",
    "# Extract the titles of the first five videos\n",
    "first_five_video_titles = []\n",
    "for link in video_links[:5]:\n",
    "    video_title = link.find_next('span', class_='style-scope ytd-grid-video-renderer').get_text()\n",
    "    first_five_video_titles.append(video_title)\n",
    "\n",
    "# Print the video titles\n",
    "for index, video_title in enumerate(first_five_video_titles, start=1):\n",
    "    print(f\"Video {index} Title: {video_title}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45dd5da-330e-4eaa-9b80-04f932bcced4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "764690e6-6c83-41b1-ba41-b4d5c5daae53",
   "metadata": {},
   "source": [
    "Q4. Write a python program to extract the number of views of the first five videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa99d931-4e4a-4390-a3b4-515de5476cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL of the YouTube channel\n",
    "url = \"https://www.youtube.com/@PW-Foundation/videos\"\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Find all elements with the class 'yt-simple-endpoint' (these are the links to videos)\n",
    "video_links = soup.find_all('a', class_='yt-simple-endpoint')\n",
    "\n",
    "# Extract the view counts of the first five videos\n",
    "first_five_view_counts = []\n",
    "for link in video_links[:5]:\n",
    "    # Find the element containing the view count\n",
    "    view_count_element = link.find_next('span', class_='style-scope ytd-grid-video-renderer')\n",
    "\n",
    "    # Extract the view count text\n",
    "    view_count_text = view_count_element.get_text()\n",
    "\n",
    "    # Extract the numeric part from the view count text\n",
    "    view_count = view_count_text.split()[0]  # Assuming view count is always in the format \"x views\"\n",
    "    first_five_view_counts.append(view_count)\n",
    "\n",
    "# Print the view counts\n",
    "for index, view_count in enumerate(first_five_view_counts, start=1):\n",
    "    print(f\"Video {index} View Count: {view_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4f1c23-0970-483d-a631-9c6d9218aefb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "021eba05-d981-45e1-9092-b9dee9da41de",
   "metadata": {},
   "source": [
    "Q5. Write a python program to extract the time of posting of video for the first five videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "876a8c67-5354-402a-9579-f8c7d7d16e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL of the YouTube channel\n",
    "url = \"https://www.youtube.com/@PW-Foundation/videos\"\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Find all elements with the class 'style-scope ytd-grid-video-renderer' (these contain posting time)\n",
    "posting_time_elements = soup.find_all('span', class_='style-scope ytd-grid-video-renderer')\n",
    "\n",
    "# Extract the time of posting of the first five videos\n",
    "first_five_posting_times = []\n",
    "for posting_time_element in posting_time_elements[:5]:\n",
    "    # Extract the posting time text\n",
    "    posting_time_text = posting_time_element.get_text()\n",
    "\n",
    "    # Extract the numeric part from the posting time text\n",
    "    posting_time = posting_time_text.strip()  # Remove leading and trailing whitespace\n",
    "    first_five_posting_times.append(posting_time)\n",
    "\n",
    "# Print the posting times\n",
    "for index, posting_time in enumerate(first_five_posting_times, start=1):\n",
    "    print(f\"Video {index} Posting Time: {posting_time}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9af896-0cc2-4b22-b4e6-964cf7f63c0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
